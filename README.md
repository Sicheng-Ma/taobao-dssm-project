# Taobao DSSM 推荐系统项目

## 项目概述

这是一个基于DSSM（Deep Structured Semantic Model）的淘宝广告推荐系统项目。项目成功解决了AUC=0.5的关键问题，并针对过拟合问题进行了深入优化。目前采用云端处理策略以充分利用大数据集。

## 问题解决历程

### 第一阶段：解决AUC=0.5问题
**原始问题**：本地采样训练结果AUC只有0.5，模型完全没有学到东西

**根本原因**：
- **数据分布不一致**：训练集和测试集的类别分布严重不一致
  - 训练集正样本比例：33.33%
  - 测试集正样本比例：5.01%
- **特征工程不足**：缺少用户行为特征等关键信息

**解决方案**：
- 实现分层采样确保训练集和测试集类别分布一致
- 优化特征工程，增加用户行为统计特征
- 调整模型超参数，使用更合适的网络结构

**结果**：AUC从0.5提升到0.54，模型开始学习

### 第二阶段：解决过拟合问题
**问题**：训练AUC达到0.8+，但验证AUC只有0.53，严重过拟合

**解决方案**：
- 简化模型架构（减少DNN层数，降低embedding维度）
- 增强正则化（提高dropout率，增加L2正则化）
- 更激进的特征选择

**结果**：过拟合程度降低，但验证AUC仍不理想

### 第三阶段：云端处理策略
**问题**：本地8GB内存无法处理22GB的behavior_log.csv文件

**解决方案**：
- 迁移到云端平台（Google Colab、Kaggle等）
- 使用更大内存和GPU资源
- 处理完整的用户行为数据

**目标**：达到基线AUC 0.622

## 项目结构

```
taobao-dssm-project/
├── data/                          # 原始数据
│   ├── ad_feature.csv            # 广告特征
│   ├── behavior_log.csv          # 用户行为日志（22GB）
│   ├── raw_sample.csv            # 原始样本
│   └── user_profile.csv          # 用户画像
├── scripts/                      # 执行脚本
│   ├── train.py                  # 主训练脚本（包含DSSM模型实现）
│   ├── process_data.py           # 云端数据处理脚本
│   └── local_sampling.py         # 本地采样脚本
├── configs/                      # 配置文件
│   └── sampling_config.py        # 采样配置
├── experiments/                  # 实验模块
│   └── upgrades/                 # 模型升级
│       ├── hard_negative_sampling.py # 困难负样本采样
│       └── sequence_transformer.py   # 序列变换器
├── outputs/                      # 输出文件
└── README.md                     # 项目说明
```

## 云端处理指南

### 推荐平台
1. **Google Colab Pro**：16GB RAM + GPU，适合中等规模处理
2. **Kaggle Notebooks**：30GB RAM + GPU，适合大规模处理
3. **AWS/GCP**：按需付费，适合生产环境

### 数据处理流程
```bash
# 1. 上传数据到云端
# 2. 运行完整数据处理
python scripts/process_data.py

# 3. 运行训练脚本
python scripts/train.py
```

### 云端配置
- **Chunk大小**：200万行/批（适合云端内存）
- **数据处理比例**：100%（充分利用大数据）
- **预期处理时间**：30-60分钟（云端环境）

## 快速开始

### 本地测试（采样版本）
```bash
# 使用现有采样数据快速验证
python scripts/train.py
```

### 云端完整训练
```bash
# 1. 上传项目到云端平台
# 2. 安装依赖
pip install pandas numpy scikit-learn tensorflow tqdm

# 3. 运行数据处理
python scripts/process_data.py

# 4. 运行训练
python scripts/train.py
```

## 关键改进

### 数据处理
- ✅ 分层采样解决类别分布不一致
- ✅ 智能特征工程
- ✅ 用户行为特征提取
- 🔄 云端大数据处理

### 模型优化
- ✅ 简化网络架构
- ✅ 增强正则化
- ✅ 特征选择优化
- 🔄 完整数据训练

### 训练策略
- ✅ 早停机制
- ✅ 学习率衰减
- ✅ 类别权重平衡
- 🔄 GPU加速训练

## 性能对比

| 版本 | 训练AUC | 验证AUC | 过拟合程度 | 状态 |
|------|---------|---------|------------|------|
| 原始版本 | 0.5 | 0.5 | 0 | ❌ 未学习 |
| 第一阶段 | 0.6+ | 0.54 | 0.06 | ✅ 开始学习 |
| 第二阶段 | 0.8+ | 0.53 | 0.35 | ⚠️ 严重过拟合 |
| 云端目标 | 0.7+ | 0.62+ | <0.1 | 🎯 目标 |

## 项目特性

### 技术栈
- **深度学习**：TensorFlow/Keras
- **数据处理**：Pandas, NumPy
- **特征工程**：Scikit-learn
- **模型架构**：DSSM双塔模型

### 核心功能
- 大规模数据处理（22GB+）
- 智能特征工程
- 深度学习推荐模型
- 云端训练支持

### 创新点
- 分层采样策略
- 用户行为特征提取
- 过拟合控制技术
- 云端处理优化

## 下一步计划

### 短期目标
1. **云端数据处理**：完成22GB behavior_log.csv处理
2. **完整模型训练**：使用全部数据训练模型
3. **性能验证**：达到基线AUC 0.622

### 中期目标
1. **模型升级**：集成experiments/upgrades目录中的改进
2. **特征优化**：进一步优化特征工程
3. **超参数调优**：使用贝叶斯优化

### 长期目标
1. **生产部署**：模型服务化
2. **A/B测试**：在线效果验证
3. **持续优化**：实时学习更新

## 贡献指南

欢迎提交Issue和Pull Request来改进项目！

## 许可证

MIT License
