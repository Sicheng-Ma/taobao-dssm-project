{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taobao DSSM Training Pipeline\n",
    "\n",
    "This notebook implements the complete training pipeline for the DSSM recommendation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Setup and Data Loading\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Add src to path for imports\n",
    "sys.path.append('/kaggle/input/dssm-project-code')\n",
    "\n",
    "# Import modules\n",
    "from src import config\n",
    "from src import data_processing\n",
    "from src import feature_engineering\n",
    "from src import model\n",
    "\n",
    "# Set data path\n",
    "DATA_PATH = f'../input/{config.DATASET_FOLDER_NAME}/'\n",
    "\n",
    "logger.info(\"Environment and modules imported successfully!\")\n",
    "logger.info(f\"Configuration loaded: BATCH_SIZE={config.BATCH_SIZE}, LEARNING_RATE={config.LEARNING_RATE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "if not os.path.exists(os.path.join(config.OUTPUT_DIR, 'train_data.csv')):\n",
    "    logger.info(\"Starting data preprocessing pipeline...\")\n",
    "    data_processing.run_pipeline(\n",
    "        data_path=DATA_PATH,\n",
    "        output_dir=config.OUTPUT_DIR,\n",
    "        chunk_size=config.CHUNKSIZE,\n",
    "        negative_ratio=config.NEG_POS_RATIO\n",
    "    )\n",
    "else:\n",
    "    logger.info(\"Data files already exist, skipping preprocessing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "\n",
    "logger.info(\"Loading data...\")\n",
    "train_df = pd.read_csv(os.path.join(config.OUTPUT_DIR, 'train_data.csv'))\n",
    "test_df = pd.read_csv(os.path.join(config.OUTPUT_DIR, 'test_data.csv'))\n",
    "\n",
    "logger.info(f\"Training data shape: {train_df.shape}\")\n",
    "logger.info(f\"Test data shape: {test_df.shape}\")\n",
    "\n",
    "# Perform feature engineering\n",
    "train_df, test_df = feature_engineering.perform_feature_engineering(\n",
    "    train_df, \n",
    "    test_df, \n",
    "    config.SPARSE_FEATURES, \n",
    "    config.DENSE_FEATURES, \n",
    "    config.OUTPUT_DIR\n",
    ")\n",
    "\n",
    "logger.info(\"Feature engineering completed!\")\n",
    "logger.info(f\"Processed training data shape: {train_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "\n",
    "# 1. Create model input dictionaries\n",
    "train_model_input = {name: train_df[name] for name in config.ALL_FEATURES}\n",
    "train_label = train_df['label'].values\n",
    "test_model_input = {name: test_df[name] for name in config.ALL_FEATURES}\n",
    "test_label = test_df['label'].values\n",
    "\n",
    "logger.info(f\"Training samples: {len(train_label)}\")\n",
    "logger.info(f\"Test samples: {len(test_label)}\")\n",
    "logger.info(f\"Positive samples in training: {train_df['label'].sum()}\")\n",
    "logger.info(f\"Positive samples in test: {test_df['label'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create feature columns\n",
    "with open(os.path.join(config.OUTPUT_DIR, 'feature_encoders.pkl'), 'rb') as f:\n",
    "    feature_encoders = pickle.load(f)\n",
    "\n",
    "# User feature columns\n",
    "user_feature_columns = [\n",
    "    model.SparseFeat(\n",
    "        name=feat, \n",
    "        vocabulary_size=len(feature_encoders[feat].classes_) + 1, \n",
    "        embedding_dim=config.EMBEDDING_DIM\n",
    "    )\n",
    "    for feat in config.USER_SPARSE_FEATURES\n",
    "]\n",
    "\n",
    "from typing import List, Union\n",
    "# Item feature columns\n",
    "item_feature_columns: List[Union[model.SparseFeat, model.DenseFeat]] = [\n",
    "    model.SparseFeat(\n",
    "        name=feat, \n",
    "        vocabulary_size=len(feature_encoders[feat].classes_) + 1, \n",
    "        embedding_dim=config.EMBEDDING_DIM\n",
    "    )\n",
    "    for feat in config.ITEM_SPARSE_FEATURES\n",
    "]\n",
    "\n",
    "# Add dense features\n",
    "item_feature_columns.append(model.DenseFeat(name='price', dimension=1))\n",
    "\n",
    "logger.info(f\"User feature columns: {len(user_feature_columns)}\")\n",
    "logger.info(f\"Item feature columns: {len(item_feature_columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Build and compile model\n",
    "dssm_model = model.DSSM(\n",
    "    user_feature_columns, \n",
    "    item_feature_columns, \n",
    "    dnn_units=config.DNN_UNITS, \n",
    "    temp=config.TEMP\n",
    ")\n",
    "\n",
    "dssm_model.summary()\n",
    "\n",
    "dssm_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=config.LEARNING_RATE), \n",
    "    loss=\"binary_crossentropy\", \n",
    "    metrics=[tf.keras.metrics.AUC(name='auc')]\n",
    ")\n",
    "\n",
    "logger.info(\"Model compiled successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Train model\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_auc', \n",
    "    mode='max', \n",
    "    patience=2, \n",
    "    verbose=1, \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "logger.info(\"Starting model training...\")\n",
    "\n",
    "history = dssm_model.fit(\n",
    "    train_model_input, \n",
    "    train_label, \n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    epochs=config.EPOCHS,\n",
    "    validation_data=(test_model_input, test_label),\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "logger.info(\"Model training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_auc = dssm_model.evaluate(test_model_input, test_label)\n",
    "logger.info(f\"Test Loss: {test_loss:.4f}\")\n",
    "logger.info(f\"Test AUC: {test_auc:.4f}\")\n",
    "\n",
    "# Save model\n",
    "model_save_path = os.path.join(config.OUTPUT_DIR, 'dssm_model')\n",
    "dssm_model.save(model_save_path)\n",
    "logger.info(f\"Model saved to: {model_save_path}\")\n",
    "\n",
    "# Save training history\n",
    "history_save_path = os.path.join(config.OUTPUT_DIR, 'training_history.pkl')\n",
    "if history is not None:\n",
    "    with open(history_save_path, 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "    logger.info(f\"Training history saved to: {history_save_path}\")\n",
    "else:\n",
    "    logger.warning(\"No training history to save\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "two_towers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
